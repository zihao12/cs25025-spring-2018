{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import time\n",
    "import itertools\n",
    "from itertools import combinations,permutations\n",
    "import scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/wangzh/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../wiki-text.txt','r') as f:\n",
    "    text = [line.split() for line in f]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "124301826"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "c_text = Counter(text[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time elapsed: 28.8972709179\n",
      "13201\n"
     ]
    }
   ],
   "source": [
    "min_threshold = 500\n",
    "#text_filter1 = [k for k, v in c_text.items() if v > min_threshold]\n",
    "start = time.time()\n",
    "text_fil1= [word for word in text[0] if not word in stop_words]\n",
    "text_filtered = [k for k in text_fil1 if c_text[k] > min_threshold]\n",
    "end = time.time()\n",
    "print(\"time elapsed: \" + str(end-start))\n",
    "print(len(set(text_filtered)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#text_filtered = text_filtered[:500]\n",
    "vocab = list(set(text_filtered))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PMI Embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###text_t = text_filtered[:5000]\n",
    "vocab_t = list(set(text_t))\n",
    "len(vocab_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_index = {}\n",
    "for i,w in enumerate(vocab):\n",
    "    vocab_index[w] = i"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First, create a word count matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import csr_matrix\n",
    "from scipy.sparse import lil_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_WW():\n",
    "    start = time.time()\n",
    "    text_t = text_filtered\n",
    "    N = len(text_t)\n",
    "    window_size = 5\n",
    " \n",
    "    WW = lil_matrix((len(vocab),len(vocab)), dtype = np.float64)\n",
    "    \n",
    "    for i, w in enumerate(text_t):\n",
    "        stepsize = min(window_size,N-i)\n",
    "        window = text_t[i:i+stepsize+1]\n",
    "        pairs = list(itertools.permutations(window,2))\n",
    "        for p in pairs:\n",
    "            WW[vocab_index[p[0]],vocab_index[p[1]]] += 1\n",
    "    \n",
    "    end = time.time()\n",
    " #   print(\"all stages complete.\")\n",
    "    print(\"time elapsed: \"+ str(end-start))\n",
    "    return(WW)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "                \n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute PMI matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time elapsed: 0.127188920975\n",
      "time elapsed: 0.348671913147\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "WW = my_WW()\n",
    "SP = WW.count_nonzero()\n",
    "WW = WW.toarray()\n",
    "Ni = WW.sum(axis = 1)\n",
    "Nis = np.diagflat(1/Ni)\n",
    "M = (WW+1)*SP\n",
    "M = np.dot(Nis,M).dot(Nis)\n",
    "M = np.log(M)\n",
    "end = time.time()\n",
    "print(\"time elapsed: \"+ str(end - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (b) k-SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time elapsed: 0.688757896423\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "U,s,V = scipy.sparse.linalg.svds(scipy.sparse.csr_matrix(M),k = 50)\n",
    "end = time.time()\n",
    "print(\"time elapsed: \"+ str(end - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (c) Word Embedding Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time elapsed: 0.000687837600708\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "ss = np.diag(np.sqrt(s))\n",
    "W = np.dot(U,ss)\n",
    "end = time.time()\n",
    "print(\"time elapsed: \"+ str(end - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (d) Find closed words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def closest_word(word,W,num=6):\n",
    "    print(\"closest words to \"+ word, \"are: \")\n",
    "    start = time.time()\n",
    "    key = vocab_index[word]\n",
    "    vec = W[key]\n",
    "    diff_W = W - np.array([vec]*W.shape[0])\n",
    "    diff = [np.dot(x,x) for x in diff_W]\n",
    "    close = np.argpartition(diff,num)[:num]\n",
    "    \n",
    "    for i in close:\n",
    "        if i!= key:\n",
    "            print(vocab[i])\n",
    "    end = time.time()\n",
    "    print(\"time elapsed: \"+ str(end-start))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('closest words to ', 'abuse', 'are: ')\n",
      "wish\n",
      "complete\n",
      "owners\n",
      "limited\n",
      "possession\n",
      "('time elapsed: ', '0.00200796127319')\n"
     ]
    }
   ],
   "source": [
    "closest_word(\"abuse\",W,6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "closest_word(\"physics\",W,6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "closest_word(\"republican\",W,6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "closest_word(\"einstein\",W,6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "closest_word(\"algebra\",W,6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "closest_word(\"fish\",W,6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (e) Solve Analogies "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve_analogies(X,Y,Z,W,num=6):\n",
    "    print(\"closest solution for analogy: \", X,\":\",Y,\"::\",Z,\":\",\"?\")\n",
    "    vec = W[vocab_index[Y]] - W[vocab_index[X]] + W[vocab_index[Z]]\n",
    "    diff_W = W - np.array([vec]*W.shape[0])\n",
    "    diff = [np.dot(x,x) for x in diff_W]\n",
    "    close = np.argpartition(diff,num)[:num]\n",
    "    \n",
    "    for i in close:\n",
    "        print(vocab[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('closest solution for analogy: ', 'france', ':', 'paris', '::', 'england', ':', '?')\n",
      "england\n",
      "london\n",
      "oxford\n",
      "dublin\n",
      "cambridge\n",
      "edinburgh\n"
     ]
    }
   ],
   "source": [
    "X = 'france'\n",
    "Y = 'paris'\n",
    "Z = 'england'\n",
    "solve_analogies(X,Y,Z,W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0251256281407\n"
     ]
    }
   ],
   "source": [
    "i = 5\n",
    "j = 199\n",
    "print(float(i)/j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float(3//5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"my_W_0\",\"rb\") as f:\n",
    "    W = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13201, 50)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
